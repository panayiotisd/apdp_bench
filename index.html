<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning">
  <meta property="og:title" content="Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning"/>
  <meta property="og:description" content="Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning"/>
  <meta property="og:url" content="https://panayiotisd.github.io/apdp_bench/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/banner_image.jpg" />
  <meta property="og:image:width" content="713"/>
  <meta property="og:image:height" content="531"/>


<!--   <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
<!--   <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image"> -->
  
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Large Language Models (LLMs), Code generation, Vibe Coding, Benchmarks, Human Evaluation">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>APDP Benchmark</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <!-- <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"> -->
  <link rel="stylesheet" href="static/css/index.css">

<!--   <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script> -->
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>


  <script defer src="https://cloud.umami.is/script.js" data-website-id="a9b877a9-ccd9-4ea0-a02a-7e30d707fd16"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://panosd.eu/" target="_blank">Panayiotis Danassis</a></sup>,</span>
                <span class="author-block">
                  <a href="https://goelnaman.github.io" target="_blank">Naman Goel</a></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Southampton, University of Oxford<br><!--Conference--></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

<!--                     <span class="link-block">
                      <a href="" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-folder"></i>
                      </span>
                      <span>Benchmark</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code for Experiments</span>
                  </a>
                </span> -->

                    <!-- Benchmark (Coming Soon) -->
              <span class="link-block">
                <a class="button is-normal is-rounded is-light" disabled style="pointer-events:none; opacity:0.6;">
                  <span class="icon">
                    <i class="fas fa-folder"></i>
                  </span>
                  <span>Benchmark (Coming Soon)</span>
                </a>
              </span>

              <!-- Code for Experiments (Coming Soon) -->
              <span class="link-block">
                <a class="button is-normal is-rounded is-light" disabled style="pointer-events:none; opacity:0.6;">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                </a>
              </span>


              <span class="agreement"><small><br>The benchmark is available under <a href="https://creativecommons.org/licenses/by/4.0/deed.en" target="_blank">CC BY 4.0</a>.</small></span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- TL;DR Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">TL;DR</h2>
        <div class="content has-text-justified">
          <p><strong>Can vibe coding with LLMs beat CS students?</strong><br>
          Short answer: Nope. Not even close.</p>

          <p>We introduce a real-world optimization benchmark, where agents manage the pickup and delivery of parcels for a logistics company. Each agent has to optimally bid for tasks sold at an auction, and plan for the pickup and delivery of the won tasks.</p>

          <p>In a massive tournament of <strong>~40,000 matches</strong>, we evaluated a range of SOTA LLM-coded agents (GPT-5 Thinking, Gemini 2.5 Pro, Claude Opus 4.1, DeepThink R1), against 17 <strong>human-coded agents, developed before the advent of LLMs</strong>, including 12 agents developed by students.</p>

          <p><strong>The results?</strong></p>

          <p>üèÜ <strong>Humans dominated.</strong><br>
          The top 5 spots are consistently won by human-coded agents.</p>

          <p>ü§ñ <strong>LLMs fell short.</strong><br>
          33 of 40 LLM-coded agents lost to simple baseline strategies.<br>
          <em>Given the best human solution as an input and prompted to improve upon, the best performing LLM makes the solution significantly worse instead of improving it.</em></p>

          <p>üéØ <strong>Takeaway:</strong> While LLMs can generate code that runs (i.e., free of syntax errors), the solution is not competitive to human-designed ones on dimensions such as strategic planning, reasoning, optimization, or multi-agent competition.</p>

          <p>It's time for a new frontier of benchmarks that go beyond passing unit tests; shifting the goal from code that compiles to code that competes.</p>
        </div>
      </div>
    </div>
  </div>
</section>




<!-- Figures section -->
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">

        <figure style="margin-bottom: 2rem;">
          <div style="margin: 0 auto; width: 70%;">
            <img src="static/images/prompt_Comparison.jpg" alt="Prompt Comparison" style="width: 100%;">
            <figcaption style="margin-top: 0.5rem; text-align: left;">
              Traditional benchmarks (top) focus on problems with clearly defined correct or incorrect solutions, typically verified through unit tests. In contrast, our benchmark (bottom) involves complex tasks such as planning, constraint optimization, modeling competitors, competitive strategy design, and advanced algorithm development ‚Äî challenges that remain highly non-trivial even for experienced software engineers. Top from Jain et al, 2025 (left) and Huynh and Lin, 2025 (right).
          </figcaption>
          </div>
        </figure>

      </div>
    </div>

  </div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The rapid proliferation of Large Language Models (LLMs) have revolutionized AI-assisted code generation. This rapid development of LLMs has outpaced our ability to properly benchmark them. Prevailing benchmarks emphasize unit-test pass rates and syntactic correctness. Such metrics understate the difficulty of many real-world problems that require <b>planning, optimization, and strategic interaction</b>. We introduce a multi-agent reasoning-driven benchmark based on a real-world logistics optimization problem (Auction, Pickup, and Delivery Problem) that couples competitive auctions with capacity-constrained routing. The benchmark requires building agents that can (i) bid strategically under uncertainty and (ii) optimize planners that deliver tasks while maximizing profit. We evaluate <i>40 LLM-coded</i> agents (by a wide range of state-of-the-art LLMs under multiple prompting methodologies, including vibe coding) against 17 <i>human-coded</i> agents developed <i>before the advent of LLMs</i>. Our results over 12 double all-play-all tournaments and <i>~40k matches</i> demonstrate (i) a clear superiority of human(graduate students)-coded agents: the <i>top 5 spots are consistently won by human-coded agents</i>, (ii) <i>the majority of LLM-coded agents (33 out of 40) are beaten by very simple baselines</i>, and (iii) given the best human solution as an input and prompted to improve upon, the best performing LLM makes the solution significantly worse instead of improving it. Our results highlight a gap in LLMs' ability to produce code <i>that works competitively in the real-world</i>, and motivate new evaluations that emphasize reasoning-driven code synthesis in real-world scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Figures section -->
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">

        <figure style="margin-bottom: 2rem;">
          <div style="margin: 0 auto; width: 70%;">
            <img src="static/images/problem_overview.jpg" alt="Problem Overview" style="width: 100%;">
            <figcaption style="margin-top: 0.5rem; text-align: left;">
              <b>The Auction, Pickup, and Delivery Problem (APDP).</b> <br><b>Task:</b> Logistic operations optimization. <b>Goal:</b> Maximize profit for a transportation company.<br>Multiple transportation companies (agents) compete in a market. Each company owns several vehicles that deliver tasks (e.g., parcels) in a given network. Tasks are sold via a reverse first-price sealed-bid auction, i.e., a company's bid corresponds to the amount of money they want to be paid to deliver the task. Higher bids mean more revenue, but biding too high may result in not getting the auctioned task. A competitive bid depends on (i) the marginal cost of adding the auctioned task to the partial delivery plan, given the already won tasks, (ii) the marginal cost of the opponent, and (iii) other strategic decisions like incurring a loss (bid below your marginal cost) at the beginning in order to reduce the cost of future tasks (better positioning in the market).<br>After the auction is complete, the company has to determine a plan for its vehicles such that all tasks won by the company are delivered and the total revenue of the company is maximized. The plan is a sequence of pickup and delivery actions, such that vehicle capacity constraints are satisfied. The total revenue of the company is defined as the sum of rewards (won bids paid out by the auction house) minus delivery cost (kilometers driven times cost per kilometer). It is, thus, necessary to bid optimally and compute efficient delivery plans.
          </figcaption>
          </div>
        </figure>

        <br><br>

        <figure style="margin-bottom: 2rem;">
          <div style="margin: 0 auto; width: 70%;">
            <img src="static/images/maps.jpg" alt="Toplogies" style="width: 100%;">
            <figcaption style="margin-top: 0.5rem; text-align: left;">
              <b>Network Topologies.</b> From top to bottom and left to right we have: Great Britain, Switzerland, the Netherlands, and France. Colored triangles represent vehicles.
          </figcaption>
          </div>
        </figure>

      </div>
    </div>

  </div>
</section>


<!-- Acknowledgements -->
<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title is-3">Acknowledgements</h2>
    <p>
      We are grateful to Professor Emeritus Boi Faltings and the members of the Artificial Intelligence Laboratory at EPFL who contributed in the development of the Intelligent Agents course over the years. We also thank the students who contributed their code as baselines, specifically: Clement Burgelin, Jonas Ulbrich, Lorenzo Jacqueroud, Alessandro Mari, Antoine Bourret, Samuel Dubuis, Oliver Facklam, Florian Singer, Manuel Leone, Stefano Huber, Wenuka Gunarathna, Sofia Dandjee, Karim Assi, Eugenie Demeure, Lorenzo Panchetti, Maxence Perret.
    </p>
  </div>
</section>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{danassis2025vibecodingtournament,
      title={Can Vibe Coding Beat Graduate CS Students? An LLM vs. Human Coding Tournament on Market-driven Strategic Planning}, 
      author={Panayiotis Danassis and Naman Goel},
      year={2025},
      eprint={},
      archivePrefix={arXiv},
      primaryClass={cs.},
      url={https://arxiv.org/abs/}, 
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

  </body>
  </html>
